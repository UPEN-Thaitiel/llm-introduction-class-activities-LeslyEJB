{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a7744d",
   "metadata": {},
   "source": [
    "### Accesing to Ollama API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373d261d",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13c50ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import dotenv\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff871476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en cmd ollama serve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b052cfbe",
   "metadata": {},
   "source": [
    "### Setting Up API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b691eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_HOST = os.getenv(\"OLLAMA_HOST\", \"http://localhost:11434\")\n",
    "MODEL = os.getenv(\"OLLAMA_MODEL\", \"deepseek-r1:8b\")  # or \"llama3.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af243bee",
   "metadata": {},
   "source": [
    "### Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "590dfe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _chat_ollama(messages, temperature=None, max_tokens=None):\n",
    "    \"\"\"\n",
    "    Minimal wrapper for Ollama /api/chat.\n",
    "    messages: list of {\"role\": \"system\"|\"user\"|\"assistant\", \"content\": str}\n",
    "    \"\"\"\n",
    "    url = f\"{OLLAMA_HOST}/api/chat\"\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False,\n",
    "        # map options similar to OpenAI\n",
    "        \"options\": {}\n",
    "    }\n",
    "    if temperature is not None:\n",
    "        payload[\"options\"][\"temperature\"] = float(temperature)\n",
    "    if max_tokens is not None:\n",
    "        payload[\"options\"][\"num_predict\"] = int(max_tokens)\n",
    "\n",
    "    r = requests.post(url, json=payload, timeout=120)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    # Ollama returns the last message in 'message'\n",
    "    return data[\"message\"][\"content\"].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "430a9b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llama32(prompt, max_tokens=50, temperature=0.3):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a concise and precise assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    return _chat_ollama(messages, temperature=temperature, max_tokens=max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdd75471",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"How are you today?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8436fa8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How are you today? <think>\n",
      "I'm an AI designed to be direct, so my response should match that style while being polite. The user asked \"How are you today?\"—they're greeting me with interest in my state.\n",
      "\n",
      "Since I don't have feelings, the\n"
     ]
    }
   ],
   "source": [
    "generated_text = ask_llama32(prompt, max_tokens=50, temperature=0.7) \n",
    "print(prompt, generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264ef2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a19f35a",
   "metadata": {},
   "source": [
    "### Summarising Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e86a4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_summarizer_llama32(prompt, temperature=0.5, max_tokens=256):\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"Extract a comma-separated list of keywords from the provided text.\"},\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": \"A flying saucer ... (same example as above)\"},\n",
    "        {\"role\": \"assistant\",\n",
    "         \"content\": \"flying saucer, guest house, 7ft alien-like figure, hedge, cigar-shaped UFO, school yard, extraterrestrial encounters, UK, mass sightings, Broad Haven, Bermuda Triangle, strange beings, late seventies, Netflix documentary, Steven Spielberg, 1977, Cold War, Star Wars, Close Encounters of the Third Kind\"},\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": \"Each April ... (same second example)\"},\n",
    "        {\"role\": \"assistant\",\n",
    "         \"content\": \"April, Maeliya, northwest Sri Lanka, banyan tree, wewa, reservoir, tank, Sinhala, rice paddies, 175-acres, rainwater, agrarian committee, coconut milk, blessings, prosperous harvest, deities, sluice gate, irrigation canals, dry months, lake-like water bodies, farmers, Sinhala phrase, village life, pagoda, temple\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    return _chat_ollama(messages, temperature=temperature, max_tokens=max_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76b99101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Reef Guide Kirsty Whitman didn't need to tell me twice. Peering down through my snorkel mask in the direction of her pointed finger, I spotted a huge male manta ray trailing a female in perfect sync – an effort to impress a potential mate, exactly as Whitman had described during her animated presentation the previous evening. Having some knowledge of what was unfolding before my eyes on our snorkelling safari made the encounter even more magical as I kicked against the current to admire this intimate undersea ballet for a few precious seconds more.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Master Reef Guide Kirsty Whitman didn't need to tell me twice. Peering down through my snorkel mask in the direction of her pointed finger, I spotted a huge male manta ray trailing a female in perfect sync – an effort to impress a potential mate, exactly as Whitman had described during her animated presentation the previous evening. Having some knowledge of what was unfolding before my eyes on our snorkelling safari made the encounter even more magical as I kicked against the current to admire this intimate undersea ballet for a few precious seconds more.\"\n",
    "print(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22a559d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, let\\'s tackle this query. The user provided a text about a snorkeling experience with manta rays and mentions Kirsty Whitman from \"Master Reef Guide.\" They want keywords extracted in CSV format.\\n\\nFirst, I need to parse the sentence carefully. Key elements here are: Master Reef Guide, Kirsty Whitman, snorkel mask, male manta ray, female manta ray, perfect sync, effort to impress a potential mate, and the previous evening\\'s presentation. Also'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_summarizer_llama32(prompt, max_tokens=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd39fb3d",
   "metadata": {},
   "source": [
    "### Coding a simple chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2608edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def poetic_chatbot_llama32(prompt, temperature=1.0, max_tokens=256):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a poetic chatbot. Answer in short rhymed couplets.\"},\n",
    "        {\"role\": \"user\", \"content\": \"When was Google founded?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"In nineteen ninety-eight the vision came to be,\\nBy Page and Brin, a search light for all to see.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Which country has the youngest president?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Austria crowned its youth with Kurz’s earnest run,\\nAt thirty-one he led, beneath a cautious sun.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    return _chat_ollama(messages, temperature=temperature, max_tokens=max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16d43869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, let me start by understanding what the user is asking. They want to know when cheese was first made. Hmm, that's an interesting historical question. First, I need to recall the earliest evidence of cheese-making dates back around 5000-6000 BCE in places like Mesopotamia or northern Europe.\\n\\nBut wait, maybe they're looking for a more specific answer? Different sources might have varying timelines. They could also be interested in different types of cheese or regional variations. Should I mention the regions where it's commonly believed to have started?\\n\\nThe user's identity isn't clear—could be a student, food enthusiast, or someone curious about history. Their actual need is straightforward: the date of the first cheese-making. But deeper down, they might want context on how cheese evolved or its cultural significance.\\n\\nI should also consider if they expect an exact year, but ancient foods don't have precise dates usually. Need to present it as an approximation with possible variations and regions. Make sure to highlight Mesopotamia and Europe since those are the main theories. Maybe mention how cheesemaking spread over time adds value by showing its historical impact beyond just a date.\\n</think>\\nFrom milk in ancient urns, we know that\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"When was cheese first made?\"\n",
    "poetic_chatbot_llama32(prompt, temperature=1.0, max_tokens=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606e7e68",
   "metadata": {},
   "source": [
    "#### Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9d3d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3775b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
